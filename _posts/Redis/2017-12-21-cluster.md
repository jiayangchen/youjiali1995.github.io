---
title: Redis源码阅读(十二) -- cluster
excerpt: 介绍 Redis 集群相关实现。
layout: post
categories: Redis
---

{% include toc %}

1. crc16(key) % 16384 slots
2. 不是自己的slot返回`moved`
3. `ping` period node_timeout / 2
4. `pfail` node_timeout * 2 `fail`
5. `clusterSendPing()` gossip一次发送n / 10 + pfail个clusterNode信息给单个结点 clusterMsg+clusterMsgDataGossip
6. ping meet 只有type不一样
`Redis`在`3.0`版本才开始支持`cluster`，之前大多使用`proxy + sentinel`实现`Redis`集群。

## 基本结构
`cluster`内部通过`Redis Cluster Bus`进行通信，端口号为`server.port+10000`。`cluster.h`中主要有下面几个结构体用于保存集群状态:
* `clusterNode`: 保存集群中单个`redis`的状态:
  * `name`: 每个节点通过40字节的`name`标志，而不是通过`ip:port`，这样即使之后改变`ip:port`也可以识别
  * 该节点负责的`slots`
  * `slaves` or `master`
  * 各种时间用于检测超时: `ping_sent`发送`ping`的时间，收到`pong`清零
  * 与该节点通信的`clusterLink`
* `clusterLink`比较简单，保存了通信用的套接字和输入输出缓冲区
* `clusterState`: 保存整个集群的状态:
  * `nodes`: `dict`类型，保存了`name`->`clusterNode`的映射
  * `slots`相关: 4个大小为16384的数据，保存了所有`slots`的信息，包括`slot`归属、迁移状态、`slot`中`key`个数；`rax *slots_to_keys`保存`slot`中对应的`key`
  * 选举相关
  * 手动`failover`相关

## 初始化
集群模式需要配置`cluster-enabled yes`，在初始化时会调用`clusterInit()`创建`server.cluster`，并以`server.port+10000`创建监听套接字，创建文件事件`clusterAcceptHandler()`。当有`redis`连接该套接字
时，会接收连接，创建`clusterLink`(注: `link->node == NULL`)，创建读事件`clusterReadHandler()`。`Redis`对待集群间通信的连接与其他连接不同，不会创建`client`。

## 集群创建
`Redis`集群创建需要下面几个步骤:
1. 使用`cluster meet <ip> <port>`将多个`redis`节点`meet`到一个`cluster`中
2. `cluster replicate <node-id>`设置主从关系
3. `cluster addslots <slot> [slot...]`分配`slot`

### cluster meet
所有的`cluster`命令都由`clusterCommand()`处理，`cluster meet`命令会调用`clusterStartHandshake()`以随机生成的`name`创建`clusterNode`，标记为`HANDSHAKE|MEET`，添加到`server.cluster->nodes`中。
真正建立连接还是在`serverCron()->clusterCron()`中:
1. 建立`tcp`连接`node->link`
2. 创建读事件`clusterReadHandler()`
3. 发送`meet`信息: `clusterSendPing()`

当接收方接收到完整消息时，会调用`clusterProcessPacket()`处理，这个函数有400多行。看一下如何处理`meet`信息:
1. 根据接收到的消息创建`clusterNode`，`HANDSHAKE`状态，添加到`server.cluster->nodes`中，但此时`node`和`link`并没有联系起来，`node->name`也为空
2. 处理`Gossip section`
3. `clusterSendPing(PONG)`

发送方收到对方发送的`pong`:
1. 更新对方的`name`
2. 更新`node->flag`，清除`handshake`状态
3. 保存`config`

要注意接收方此时没有将`node`和`link`联系起来，也就是`node->link == null`，会在`clusterCron()`中新建连接，发送`ping`，当收到`pong`时和上述一样，这时才会清除`handshake`状态。这相当于一次4次握手的过程，
原因和`TCP`3次握手相同，为了建立可靠的连接、防止过期`meet`信息影响。不用3次握手的原因，应该是为了机制的统一和复用代码，也避免了增加一种消息类型。  

比较奇怪的是，节点之间通过建立了2个连接进行通信，`node->link`是在`clusterCron()`中主动连接时建立的；而接收连接时建立的`link`，没有与之关联的`node`，也就是一方的`node->link`对应的另一方的`link->node == NULL`。
![image](/assets/images/cluster_link.png)

不用一个连接的原因，我猜测如下: 由于网络的不确定性，当收到对方的请求时，`link->node == NULL`；当收到自己发送的请求的响应时，`link->node != NULL`。
```
This means that the cluster is able to auto-discover other nodes, but only if there is a trusted relationship that was forced by the system administrator.
只有`cluster meet`进来的或者是`cluster meet`进来的`gossip`包含的才会`clusterAddNode`，被`trusted`
`gossip`包含的未知的`clusterStartHandshake()`
```

### cluster replicate
第二步是调用`cluster replicate <node-id>`建立主从关系，需要满足下面条件才能建立成功:
* 当前节点: `slots`和`db0`都为空
* 目标节点: 已知且为`master`

然后调用`clusterSetMaster()`，设置主从关系:
1. 更新`flag`: `CLUSTER_NODE_SLAVE`
2. 设置自己的`myself->slaveof`，调用`clusterNodeAddSlave()`
2. 调用`replicationSetMaster()`，主从复制的过程和单机一样
要注意这时候`master`和`slave`并没有通知主从关系，会在之后的`heartbeat`中通知到集群中的所有节点，进行设置。

### cluster addslots
第三部调用`cluster addslots <slot> [slot...]`增加负责的`slot`。`slot`在`Redis`内部有两部分保存:
1. `clusterState`中保存集群中所有`slots`的状态:
```c
    clusterNode *migrating_slots_to[CLUSTER_SLOTS];
    clusterNode *importing_slots_from[CLUSTER_SLOTS];
    clusterNode *slots[CLUSTER_SLOTS];
    uint64_t slots_keys_count[CLUSTER_SLOTS];
    rax *slots_to_keys;
```
2. `clusterNode`中以`bitmap`保存自己负责的`slot`:
```
    unsigned char slots[CLUSTER_SLOTS/8]; /* slots handled by this node */
```

>Note that once a node assigns a set of slots to itself, it will start propagating this information in heartbeat packet headers. 
However the other nodes will accept the information only if they have the slot as not already bound with another node,
or if the configuration epoch of the node advertising the new hash slot, is greater than the node currently listed in the table.

## 集群服务
1. crc16 16384slots
2. -moved
3. aof / rdb
4. 迁移-ask asking

## clusterCron

10 times every second:
1. 处理`handshake`超时`freeClusterNode()`
2. `node->link`断开或还未建立时，建立连接，发送`ping`/`meet`
3. 每调用`clusterCron()`10次，随机选择`nodje->pong_received`最小的节点发送`ping`(每秒发送一次)
4. 统计`orphaned master`个数，`max_slaves`个数，当前`master`的`slave`个数
5. 发送过`ping`且超过`cluster_node_timeout/2`时间没收到`pong`的，释放`link`，会在下次`clusterCron()`中上述第2步重新发送`ping`，重新发送`ping`不会改变`ping_sent`
```c
    old_ping_sent = node->ping_sent;
    clusterSendPing(link, node->flags & CLUSTER_NODE_MEET ?
            CLUSTERMSG_TYPE_MEET : CLUSTERMSG_TYPE_PING);
    if (old_ping_sent) {
        /* If there was an active ping before the link was
            * disconnected, we want to restore the ping time, otherwise
            * replaced by the clusterSendPing() call. */
        node->ping_sent = old_ping_sent;
    }
```
6. 没发送`ping`，超过`cluster_node_timeout/2`时间的节点发送`ping`
7. 发送`ping`超过`cluster_node_timeout`未收到`pong`，标记为`pfail`
8. 重连`master`? 3440
9. `failover`
10. `slave migrate`

## Gossip

`cluster config file`保存`cluster nodes`信息和`var currentEpoch(cluster->currentEpoch) lastVoteEpoch(cluster->lastVoteEpoch)`

cluster nodes:
name ip:port@cport flags -/slaveof.name node->ping_send node->pong_received node->configEpoch link-status(connected/disconnected) slots

`currentEpoch`: `clusterState->currentEpoch`  

`configEpoch`: `master->configEpoch`  

接收到会更新，`configEpoch`更新会调用`clusterDoBeforeSleep(save|fsync config)`将当前信息保存到config file
每当有`node`重连会调用clusterUpdateState更新`cluster`可用状态?

`clusterMsg`由2部分组成:
* `header`: 包含当前节点的信息
* `data`: `union`4种消息:
 * `ping`
 * `fail`
 * `publish`
 * `update`

 ```c
typedef struct {
    char sig[4];        /* Siganture "RCmb" (Redis Cluster message bus). */
    uint32_t totlen;    /* Total length of this message */
    uint16_t ver;       /* Protocol version, currently set to 1. */
    uint16_t port;      /* TCP base port number. */
    uint16_t type;      /* Message type */
    uint16_t count;     /* Only used for some kind of messages. */
    uint64_t currentEpoch;  /* The epoch accordingly to the sending node. */
    uint64_t configEpoch;   /* The config epoch if it's a master, or the last
                               epoch advertised by its master if it is a
                               slave. */
    uint64_t offset;    /* Master replication offset if node is a master or
                           processed replication offset if node is a slave. */
    char sender[CLUSTER_NAMELEN]; /* Name of the sender node */
    unsigned char myslots[CLUSTER_SLOTS/8];
    char slaveof[CLUSTER_NAMELEN];
    char myip[NET_IP_STR_LEN];    /* Sender IP, if not all zeroed. */
    char notused1[34];  /* 34 bytes reserved for future usage. */
    uint16_t cport;      /* Sender TCP cluster bus port */
    uint16_t flags;      /* Sender node flags */
    unsigned char state; /* Cluster state from the POV of the sender */
    unsigned char mflags[3]; /* Message flags: CLUSTERMSG_FLAG[012]_... */
    union clusterMsgData data;
} clusterMsg;
 ```

`clusterMsg header`: `clusterBuildMessageHdr()`

集群间通信将整个结构体发送过去，需要注意字节序、操作系统和体系结构。接收时，会首先接收前8个字节，获取消息长度，之后再读取完整消息。

`ping`、`pong`、`meet`消息内容都一样，只有类型不同，`meet`会强制接收者将该节点加入集群结构中。这三种消息附带`clusterMsgDataGossip`类型消息，会附带当前已知的集群结点中随机
选择1/10个的节点信息(至少3个，且不包含接收者和发送者)，还有所有的`pfail`节点。
>
        /* In the gossip section don't include:
         * 1) Nodes in HANDSHAKE state.
         * 3) Nodes with the NOADDR flag set.
         * 4) Disconnected nodes if they don't have configured slots.
         */



## migrate

## 高可用
1. fail
2. failover
3. slave migrate

